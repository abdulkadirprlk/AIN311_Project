{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AIN311: Fundamentals of Machine Learning Project (Fall 2024)\n",
    "### Abdulkadir Parlak - 2210765025\n",
    "### Talha Kaba - 2210765037"
   ],
   "id": "87b029cb8641d874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Necessary Imports",
   "id": "76f64d01e872bfcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "83dd74cdefdd0abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) == 0:\n",
    "    raise RuntimeError(\"No GPU detected. Please enable GPU in the Kaggle environment.\")"
   ],
   "id": "db0efd00ad38bf38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "base_dir = \"/kaggle/input/punch-detection-data-frames-scaled-180x180/Consolidated_Scaled_Data\"\n",
    "scaled_images_folder = \"scaled_images\"\n",
    "scaled_annotations_file = \"scaled_annotations.json\""
   ],
   "id": "2786a0d607d13c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize lists for data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load the JSON annotations\n",
    "def parse_annotations(json_file):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    annotations = {}\n",
    "    for track in data:\n",
    "        for item in track.get(\"tracks\", []):\n",
    "            label = item.get(\"label\")\n",
    "            if label:\n",
    "                for shape in item.get(\"shapes\", []):\n",
    "                    frame = shape.get(\"frame\")\n",
    "                    if frame is not None:\n",
    "                        annotations[f\"{frame}_cropped.jpg\"] = label\n",
    "    return annotations"
   ],
   "id": "e0d9c6b576e8d1a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Process each task folder\n",
    "for task_dir in os.listdir(base_dir):\n",
    "    task_path = os.path.join(base_dir, task_dir)\n",
    "\n",
    "    if os.path.isdir(task_path):\n",
    "        image_dir = os.path.join(task_path, scaled_images_folder)\n",
    "        annotation_path = os.path.join(task_path, scaled_annotations_file)\n",
    "\n",
    "        # Debugging: Check if directories and files exist\n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"Image directory not found: {image_dir}\")\n",
    "            continue\n",
    "        if not os.path.exists(annotation_path):\n",
    "            print(f\"Annotation file not found: {annotation_path}\")\n",
    "            continue\n",
    "\n",
    "        # Parse annotations\n",
    "        frame_annotations = parse_annotations(annotation_path)\n",
    "\n",
    "        # Load images and corresponding labels\n",
    "        for image_name, label in frame_annotations.items():\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                # Load and preprocess image\n",
    "                try:\n",
    "                    img = load_img(image_path, target_size=(180, 180))\n",
    "                    img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "            else:\n",
    "                print(f\"Image file not found: {image_path}\")"
   ],
   "id": "6930fb828f671075"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Map labels to integers for classification\n",
    "classes = [\n",
    "    \"Head with left hand\", \"Head with right hand\",\n",
    "    \"Body with left hand\", \"Body with right hand\",\n",
    "    \"Block with left hand\", \"Block with right hand\",\n",
    "    \"Miss with left hand\", \"Miss with right hand\"\n",
    "]\n",
    "class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
    "labels = [class_to_index[label] for label in labels]\n",
    "\n",
    "# Debugging: Check if images and labels were loaded\n",
    "print(f\"Total images loaded: {len(images)}\")\n",
    "print(f\"Total labels loaded: {len(labels)}\")\n",
    "\n",
    "# Ensure data is available\n",
    "if len(images) == 0 or len(labels) == 0:\n",
    "    raise ValueError(\"No images or labels were loaded. Please check the dataset structure and file paths.\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "images = np.array(images, dtype=np.float32)\n",
    "labels = np.array(labels, dtype=np.int32)"
   ],
   "id": "2da57d2a840794f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Split data into training (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ],
   "id": "cb6362117b4dcb8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Model",
   "id": "26f9b4853e33df50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=90, kernel_size=(3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=180, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=180, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=180, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=8, activation='softmax')  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "id": "e08fcf478c9a0777"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model",
   "id": "6f8811048ce7ebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model explicitly on GPU with epochs=10 and batch_size=32\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=10,\n",
    "        batch_size=32\n",
    "    )"
   ],
   "id": "a82032c9d6497623"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the Model",
   "id": "1aeca1b2b66a855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate the model\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    # Calculate accuracy and final loss\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "    print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Calculate other evaluation metrics\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Display classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=classes))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    # Display confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ],
   "id": "4ab8ed9afeee213e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
